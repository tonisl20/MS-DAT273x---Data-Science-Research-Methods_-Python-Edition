{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 3, Lab 1 - Frequency Claims\n",
    "==================================\n",
    "\n",
    "In this lab, we will examine how to analyze data for a frequency claim.\n",
    "A frequency claim is where the level of a single variable is reported.\n",
    "\n",
    "In this example, you are analyzing data from a local coffee company. You\n",
    "wish to know how many coffee beverages are consumed by the average\n",
    "customer in a day. These customers are surveyed and the data are\n",
    "produced. You load the data from a CSV file (in the datasets github folder for\n",
    "this lab).\n",
    "\n",
    "The packages are loaded as a first step. You can safely ignore any deprecation warning which may appear depending on the version of the `statsmodels` package being loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD PACKAGES ####\n",
    "## Use inline magic command so plots appear in the data frame\n",
    "%matplotlib inline\n",
    "\n",
    "## Next the packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our data as a Pandas data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD DATA ####\n",
    "dat = pd.read_csv(\"datasets/cupsdat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You inspect the data using the Pandas `columns` attribute and `head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dat.columns)\n",
    "\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an ID variable called `Unnamed` and a variable indicating the number of\n",
    "beverages named `count`.\n",
    "\n",
    "The first thing to do is to explore the variable. The Pandas `describe()`\n",
    "method has many useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that scores range from 0-7, with a median (50% quantile) of 2.\n",
    "\n",
    "Exploring Counts\n",
    "================\n",
    "\n",
    "We can also use the `value_counts()` method on a Pandas series (single column of vector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a sense of the distribution. The values are in the left column and the counts in the right column. \n",
    "\n",
    "Often, stakeholders want percentages. This is easy to accomplish, provided you know how many responses you have. The number of rows in the data frame can be returned as the first value of the shape attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you could ask for the `len()` of the `dat$count` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dat['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, I would avoid these as there could be missing values in the data frame. Treating missing values in Pandas data frames is a bit complicated as there can be multiple ways missing values are coded. The simple general recipe for finding and treating missing values is:\n",
    "1. Determine how missing values are coded. They might be coded as `numpy.nan` (not a number), `numpy.inf` (infinity) or some other code.\n",
    "2. Convert all missing values to `numpy.nan` values.\n",
    "3. Use the Pandas `dropna()` method.   \n",
    "\n",
    "Following this recipe, the percentages of each value can be given by dividing each count by\n",
    "the total is computed as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove rows with nan without making copy of the data frame\n",
    "dat.dropna(axis = 0, inplace = True) \n",
    "\n",
    "## Now get the counts into a data frame sorted by the number\n",
    "count_frame = dat['count'].value_counts()\n",
    "count_frame = pd.DataFrame({'number':count_frame.index, 'counts':count_frame}).sort_values(by = 'number')\n",
    "\n",
    "## Compute the percents for each number\n",
    "n = len(dat['count'])\n",
    "count_frame['percents'] = [100* x/n for x in count_frame['counts']]\n",
    "\n",
    "## Print as a nice table\n",
    "count_frame[['number', 'percents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it can sometimes be helpful to generate a cumulative\n",
    "percentage. This can be done with the `cumsum()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a cumsum dat\n",
    "count_frame['cumsums'] = count_frame['percents'].cumsum()\n",
    "## Print as a nice table\n",
    "count_frame[['number', 'percents', 'cumsums']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here easily that 60% of the sample has consumed 2 drinks per day\n",
    "or fewer. This is a very handy little chart.\n",
    "\n",
    "Histogram\n",
    "=========\n",
    "\n",
    "The most common data visualization is a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dat['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M3_Lab1_-_Frequency_files/figure-markdown_strict/unnamed-chunk-12-1.png)\n",
    "\n",
    "We see here that the most common score is 1 and that that data has considerable skew. But, notice there are gaps in the histogram bars. You know from the frequency table that there should be no gaps. \n",
    "\n",
    "The problem with the above histogram is that the default number of bins was used. Using 8 bins (for the 8 possible count values) will give a more representative histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dat['count'], bins = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M3_Lab1_-_Frequency_files/figure-markdown_strict/unnamed-chunk-13-1.png)\n",
    "\n",
    "This looks both professional and more accurate. Changing plot properties can change your perception of data.\n",
    "\n",
    "To make a better graph for a presentation you can add plot attributes, such as axis labels and a title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dat['count'], bins = 8)\n",
    "plt.title('Frequency of number of cups of coffee consumed')\n",
    "plt.xlabel('Cups of coffee per day')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Central Tendency\n",
    "================\n",
    "\n",
    "Assuming you want to provide a one-number summary, you can provide an\n",
    "average. However, we see here given the skew that the mean will be\n",
    "biased upwards.\n",
    "\n",
    "Using the `skew()` function from the `scipy.stats` package, we can see this is\n",
    "a modestly skewed distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(dat['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is within acceptable range for many purposes (any analyses start to\n",
    "worry when skew reaches somewhere between 0.80-2.0). You can compute the mean and median of an array using the Numpy `mean()` and `median()` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(dat['count']))\n",
    "print(np.median(dat['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you finish, you might want to put a confidence interval around\n",
    "the mean. You can use the `CI()` command from the `Rmisc` package,\n",
    "which works well for analysis when you plan to analyze the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.DescrStatsW(list(dat['count'])).tconfint_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wished to provide a CI for a median, or if your data are\n",
    "proportions or some other format than these, there are many easy options\n",
    "that can be found with a brief web search, similar to the above.\n",
    "\n",
    "Conclusion\n",
    "==========\n",
    "\n",
    "In this case, we can make a frequency claim: most people, on average\n",
    "consume 1-2 cups of coffee per day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
